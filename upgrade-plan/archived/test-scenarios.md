# 测试场景

## 1. 基本任务执行流程

### 场景描述
用户发送消息给 Chat Apps，mainAgent 分析后创建 subagent 执行任务，subagent 完成后返回结果。

### 测试步骤

1. **启动 nanobot 服务**
   ```bash
   nanobot gateway
   ```

2. **用户发送任务消息**
   - 消息："帮我搜索最近一周关于人工智能的新闻"

3. **验证 mainAgent 分析**
   - 检查 mainAgent 是否识别到需要创建子代理
   - 验证子代理创建成功

4. **监控任务执行**
   - 查看子代理执行进度
   - 检查任务状态更新

5. **验证结果返回**
   - 确认子代理完成后返回正确结果
   - 检查结果格式是否符合预期

## 2. 任务修正场景

### 场景描述
用户先发送一个任务，在任务执行过程中发送新消息修改任务要求，subagent 根据新消息修正工作。

### 测试步骤

1. **发送第一个任务消息**
   - 消息："帮我搜索关于人工智能的新闻"

2. **等待子代理开始执行**
   - 监控任务状态变为运行中

3. **发送修正消息**
   - 消息："改成搜索关于机器学习的新闻"

4. **验证任务修正**
   - 检查子代理是否接收并处理新消息
   - 验证任务参数是否更新

5. **检查最终结果**
   - 确认返回结果符合修正后的要求

## 3. 多任务并发执行

### 场景描述
用户同时发送多个任务消息，系统能够正确管理多个并发子代理。

### 测试步骤

1. **发送多个任务消息**
   - 消息1："搜索人工智能新闻"
   - 消息2："查看天气情况"
   - 消息3："检查待办事项"

2. **监控任务状态**
   - 确认所有任务同时创建和运行
   - 检查任务状态管理是否正常

3. **验证执行顺序**
   - 检查任务是否按照合理的顺序执行
   - 确认系统资源使用在合理范围内

4. **确认结果返回**
   - 每个任务完成后都返回正确结果
   - 结果与任务的对应关系正确

## 4. 监控任务触发和执行

### 场景描述
Cron Job 每小时触发一次，检查任务执行状态和进度。

### 测试步骤

1. **手动触发监控任务**
   ```bash
   nanobot cron run task-progress-monitor
   ```

2. **检查监控执行**
   - 确认监控任务成功触发
   - 检查执行过程日志

3. **验证监控结果**
   - 确认监控任务返回任务状态摘要
   - 检查是否有任务状态异常报告

4. **自动触发验证**
   - 等待 cron 定时触发（1小时后）
   - 验证任务自动执行

## 5. 任务失败自动修复

### 场景描述
任务执行过程中出现故障，监控任务检测到后自动修正和重新执行。

### 测试步骤

1. **创建故障场景**
   - 发送一个需要外部 API 的任务
   - 模拟 API 服务不可用

2. **等待任务失败**
   - 检查任务状态变为失败
   - 确认错误信息记录

3. **监控任务检测**
   - 触发监控任务
   - 验证监控任务检测到失败的任务

4. **自动修复验证**
   - 确认监控任务尝试修复任务
   - 检查任务是否重新执行

5. **最终状态验证**
   - 任务恢复后状态变为完成
   - 返回正确结果

## 6. 性能测试场景

### 场景描述
测试系统在高负载下的性能表现。

### 测试步骤

1. **并发任务测试**
   - 同时发送 10 个任务消息
   - 监控系统资源使用（CPU、内存、磁盘）

2. **响应时间测试**
   - 测量消息到子代理创建的时间
   - 测量任务执行到结果返回的时间

3. **资源消耗测试**
   - 检查子代理执行时的资源消耗
   - 验证资源释放是否正常

4. **稳定性测试**
   - 长时间运行大量任务
   - 检查系统是否稳定运行

## 7. 边界条件测试

### 场景描述
测试系统在边界条件下的处理能力。

### 测试步骤

1. **非常长时间运行的任务**
   - 发送需要数小时才能完成的任务
   - 验证任务状态跟踪和进度汇报

2. **非常短的任务**
   - 发送耗时小于 1 秒的任务
   - 确认系统能够正确处理

3. **大量小任务**
   - 发送大量简单的小任务
   - 检查系统吞吐量和响应时间

## 8. 兼容性测试

### 场景描述
验证新功能与现有功能的兼容性。

### 测试步骤

1. **现有技能兼容性**
   - 测试使用现有技能的任务
   - 确认技能执行正常

2. **现有工具兼容性**
   - 测试使用现有工具的任务
   - 确认工具调用和返回结果正确

3. **配置文件兼容性**
   - 测试使用现有配置文件
   - 确认系统能够正常加载和运行

4. **API 兼容性**
   - 测试使用现有 API 的功能
   - 确认接口调用和返回格式

## 测试工具和方法

### 1. 自动化测试

```bash
# 运行单元测试
pytest tests/test_task_manager.py -v
pytest tests/test_message_analyzer.py -v
pytest tests/test_subagent_enhanced.py -v
pytest tests/test_task_monitor.py -v

# 运行集成测试
pytest tests/integration/ -v
```

### 2. 性能测试工具

- **Locust**：用于压力测试和负载测试
- **JMeter**：用于模拟并发请求
- **cProfile**：用于性能分析

### 3. 监控和分析工具

- **Prometheus + Grafana**：用于系统监控和可视化
- **ELK Stack**：用于日志收集和分析
- **psutil**：用于资源使用监控

## 测试数据准备

### 1. 任务类型

- **信息搜索任务**：需要搜索和信息提取的任务
- **数据处理任务**：需要计算和数据处理的任务
- **外部 API 任务**：需要调用外部服务的任务
- **长时间运行任务**：耗时较长的任务

### 2. 测试消息示例

```json
[
  {"type": "info_search", "content": "搜索最近一周关于人工智能的新闻"},
  {"type": "data_processing", "content": "计算过去一个月的销售数据"},
  {"type": "external_api", "content": "查询天气信息"},
  {"type": "long_running", "content": "训练一个简单的机器学习模型"}
]
```

## 测试报告模板

### 测试结果汇总

| 测试场景 | 测试结果 | 问题数量 | 备注 |
|---------|---------|---------|------|
| 基本任务执行流程 | ✅ 成功 | 0 | |
| 任务修正场景 | ✅ 成功 | 0 | |
| 多任务并发执行 | ✅ 成功 | 0 | |
| 监控任务触发和执行 | ✅ 成功 | 0 | |
| 任务失败自动修复 | ✅ 成功 | 0 | |

### 性能测试结果

| 指标 | 平均值 | 最大值 | 最小值 | 备注 |
|------|--------|--------|--------|------|
| 任务创建时间 | 230ms | 450ms | 120ms | |
| 任务执行时间 | 15.3s | 45.2s | 2.1s | |
| 系统 CPU 使用率 | 45% | 85% | 10% | |
| 系统内存使用率 | 60% | 85% | 40% | |
