# ä¸Šä¸‹æ–‡ç›‘æ§é’©å­è®¾è®¡

## ğŸ“‹ éœ€æ±‚è¯´æ˜

æ·»åŠ ä¸€ä¸ªé»˜è®¤é’©å­æˆ–é…ç½®ï¼Œå½“ä¸Šä¸‹æ–‡é•¿åº¦è¾¾åˆ°çª—å£çš„ 60% æ—¶è§¦å‘ä¸Šä¸‹æ–‡ç®¡ç†ç¨‹åºï¼Œä½¿ç”¨å½“å‰çš„ä¸Šä¸‹æ–‡ç®¡ç†ä½“ç³»ç®¡ç†è¾“å…¥çš„å†…å®¹ã€‚

---

## ğŸ¯ è®¾è®¡ç›®æ ‡

1. **å®æ—¶ç›‘æ§** - åœ¨æ¯æ¬¡æ·»åŠ æ¶ˆæ¯åæ£€æŸ¥ä¸Šä¸‹æ–‡é•¿åº¦
2. **é˜ˆå€¼è§¦å‘** - å½“è¾¾åˆ°çª—å£çš„ 60% æ—¶è‡ªåŠ¨è§¦å‘å‹ç¼©
3. **æ™ºèƒ½å‹ç¼©** - ä½¿ç”¨å·²æœ‰çš„ ContextCompressorV2 è¿›è¡Œå‹ç¼©
4. **å¯é…ç½®** - æ”¯æŒè‡ªå®šä¹‰é˜ˆå€¼å’Œå‹ç¼©ç­–ç•¥

---

## ğŸ—ï¸ æ ¸å¿ƒè®¾è®¡

### 1. ä¸Šä¸‹æ–‡ç›‘æ§å™¨ï¼ˆContextMonitorï¼‰

```python
import logging
from typing import List, Dict, Optional, Callable
from datetime import datetime

class ContextMonitor:
    """
    ä¸Šä¸‹æ–‡ç›‘æ§å™¨

    åŠŸèƒ½ï¼š
    - ç›‘æ§ä¸Šä¸‹æ–‡é•¿åº¦
    - å½“è¾¾åˆ°é˜ˆå€¼æ—¶è§¦å‘å‹ç¼©
    - ä½¿ç”¨ ContextCompressorV2 è¿›è¡Œå‹ç¼©
    - æ”¯æŒè‡ªå®šä¹‰é’©å­
    """

    def __init__(
        self,
        context_compressor,
        max_tokens: int = 128000,  # Claude 3.5 Sonnet é»˜è®¤çª—å£
        threshold_percent: float = 0.6,  # 60% é˜ˆå€¼
        hooks: Optional["HookSystem"] = None
    ):
        """
        åˆå§‹åŒ–ä¸Šä¸‹æ–‡ç›‘æ§å™¨

        Args:
            context_compressor: ä¸Šä¸‹æ–‡å‹ç¼©å™¨å®ä¾‹
            max_tokens: ä¸Šä¸‹æ–‡çª—å£æœ€å¤§ token æ•°
            threshold_percent: è§¦å‘å‹ç¼©çš„é˜ˆå€¼ç™¾åˆ†æ¯”
            hooks: é’©å­ç³»ç»Ÿå®ä¾‹
        """
        self.compressor = context_compressor
        self.max_tokens = max_tokens
        self.threshold = max_tokens * threshold_percent
        self.hooks = hooks or HookSystem()
        self.logger = logging.getLogger(__name__)

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_checks": 0,
            "compressions_triggered": 0,
            "messages_compressed": 0,
            "tokens_saved": 0
        }

        # æ³¨å†Œé»˜è®¤é’©å­
        self._register_default_hooks()

    def check_and_compress(
        self,
        messages: List[Dict],
        compress_system: bool = False
    ) -> List[Dict]:
        """
        æ£€æŸ¥å¹¶å‹ç¼©ä¸Šä¸‹æ–‡

        Args:
            messages: å½“å‰æ¶ˆæ¯åˆ—è¡¨
            compress_system: æ˜¯å¦å‹ç¼©ç³»ç»Ÿæ¶ˆæ¯ï¼ˆé€šå¸¸ä¸å‹ç¼©ï¼‰

        Returns:
            å‹ç¼©åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        self.stats["total_checks"] += 1

        # è®¡ç®—å½“å‰ token æ•°
        current_tokens = self._count_tokens(messages)

        self.logger.debug(
            "Context check: %d / %d tokens (%.1f%%)",
            current_tokens,
            self.max_tokens,
            current_tokens / self.max_tokens * 100
        )

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é˜ˆå€¼
        if current_tokens >= self.threshold:
            self.logger.info(
                "Context threshold reached (%.1f%%, triggering compression",
                current_tokens / self.max_tokens * 100
            )

            # è§¦å‘å‹ç¼©å‰é’©å­
            self.hooks.trigger(
                "before_context_compression",
                current_tokens=current_tokens,
                max_tokens=self.max_tokens,
                threshold=self.threshold=self.threshold,
                messages_count=len(messages)
            )

            # æ‰§è¡Œå‹ç¼©
            compressed_messages, stats = self._compress_messages(
                messages,
                compress_system=compress_system
            )

            # æ›´æ–°ç»Ÿè®¡
            self.stats["compressions_triggered"] += 1
            self.stats["messages_compressed"] += len(messages) - len(compressed_messages)
            self.stats["tokens_saved"] += current_tokens - self._count_tokens(compressed_messages)

            # è§¦å‘å‹ç¼©åé’©å­
            self.hooks.trigger(
                "after_context_compression",
                original_count=len(messages),
                compressed_count=len(compressed_messages),
                original_tokens=current_tokens,
                compressed_tokens=self._count_tokens(compressed_messages),
                compression_ratio=stats.compression_ratio
            )

            # è®°å½•å‹ç¼©ç»“æœ
            self.logger.info(
                "Context compressed: %d â†’ %d messages (%.1f%% ratio, %d tokens saved)",
                len(messages),
                len(compressed_messages),
                stats.compression_ratio * 100,
                self._count_tokens(messages) - self._count_tokens(compressed_messages)
            )

            return compressed_messages

        return messages

    def _count_tokens(self, messages: List[Dict]) -> int:
        """
        è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„æ€» token æ•°

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ€» token æ•°
        """
        total = 0
        for msg in messages:
            content = msg.get("content", "")
            if isinstance(content, str):
                total += self.compressor.count_tokens(content)
            elif isinstance(content, list):
                # å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ï¼‰
                for item in content:
                    if item.get("type") == "text":
                        text = item.get("text", "")
                        total += self.compressor.count_tokens(text)
                    # å›¾ç‰‡ token è®¡ç®—éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
                    elif item.get("type") == "image_url":
                        total += 85  # å‡è®¾æ¯å¼ å›¾ç‰‡çº¦ 85 tokensï¼ˆClaude 3ï¼‰
        return total

    def _compress_messages(
(
        self,
        messages: List[Dict],
        compress_system: bool = False
    ) -> tuple:
        """
        å‹ç¼©æ¶ˆæ¯åˆ—è¡¨

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            compress_system: æ˜¯å¦å‹ç¼©ç³»ç»Ÿæ¶ˆæ¯

        Returns:
            (å‹ç¼©åçš„æ¶ˆæ¯åˆ—è¡¨, å‹ç¼©ç»Ÿè®¡ä¿¡æ¯)
        """
        # åˆ†ç¦»ç³»ç»Ÿæ¶ˆæ¯å’Œå…¶ä»–æ¶ˆæ¯
        system_messages = []
        other_messages = []

        for msg in messages:
            if msg.get("role") == "system":
                system_messages.append(msg)
            else:
                other_messages.append(msg)

        # ç¡®å®šå‹ç¼©ç›®æ ‡
        if compress_system:
            # å‹ç¼©æ‰€æœ‰æ¶ˆæ¯ï¼ˆåŒ…æ‹¬ç³»ç»Ÿæ¶ˆæ¯ï¼‰
            target_messages = messages
            compressed_messages, stats = self.compressor.compress_messages(
                target_messages,
                max_tokens=int(self.max_tokens * 0.8)  # ç•™ 20% ä½™é‡
            )
        else:
            # åªå‹ç¼©éç³»ç»Ÿæ¶ˆæ¯
            compressed_other, stats = self.compressor.compress_messages(
                other_messages,
                max_tokens=int(self.max_tokens * 0.8) - self._count_tokens(system_messages)
            )
            # é‡æ–°ç»„åˆ
            compressed_messages = system_messages + compressed_other

        return compressed_messages, stats

    def _register_default_hooks(self):
        """æ³¨å†Œé»˜è®¤é’©å­"""
        # å‹ç¼©å‰é’©å­ï¼šè®°å½•æ—¥å¿—
        self.hooks.register(
            "before_context_compression",
            self._on_before_compression
        )

        # å‹ç¼©åé’©å­ï¼šè®°å½•æ—¥å¿—å¹¶ä¿å­˜è°ƒè¯•ä¿¡æ¯
        self.hooks.register(
            "after_context_compression",
            self._on_after_compression
        )

    def _on_before_compression(self, **kwargs):
        """å‹ç¼©å‰é»˜è®¤å¤„ç†"""
        current_tokens = kwargs.get("current_tokens", 0)
        threshold = kwargs.get("threshold", 0)

        self.logger.info(
            "Context compression triggered: %d tokens (threshold: %d tokens, %.1f%%)",
            current_tokens,
            int(threshold),
            current_tokens / threshold * 100
        )

    def _on_after_compression(self, **kwargs):
        """å‹ç¼©åé»˜è®¤å¤„ç†"""
        original_count = kwargs.get("original_count", 0)
        compressed_count = kwargs.get("compressed_count", 0)
        original_tokens = kwargs.get("original_tokens", 0)
        compressed_tokens = kwargs.get("compressed_tokens", 0)
        compression_ratio = kwargs.get("compression_ratio", 0)

        self.logger.info(
            "Context compressed: %d â†’ %d messages (%.1f%%, %d â†’ %d tokens)",
            original_count,
            compressed_count,
            compression_ratio * 100,
            original_tokens,
            compressed_tokens
        )

    def get_stats(self) -> Dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return self.stats.copy()

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            "total_checks": 0,
            "compressions_triggered": 0,
            "messages_compressed": 0,
            "tokens_saved": 0
        }
```

---

## ğŸ”§ é›†æˆåˆ° Agent Loop

### ä¿®æ”¹åçš„ AgentLoop ç±»

```python
class AgentLoop:
    """
    Agent æ¶ˆæ¯å¾ªç¯ï¼Œé›†æˆä¸Šä¸‹æ–‡ç›‘æ§
    """

    def __init__(self, agent, context_monitor: Optional[ContextMonitor] = None):
        self.agent = agent
        self.context_monitor = context_monitor
        self.messages: List[Dict] = []

    async def process_message(self, message: str, media: List[str] = None) -> str:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            media: é™„ä»¶ï¼ˆå›¾ç‰‡ç­‰ï¼‰

        Returns:
            åŠ©æ‰‹å›å¤
        """
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_message = {"role": "user", "content": message}
        if media:
            # å¤„ç†å¤šæ¨¡æ€å†…å®¹
            user_message["content"] = self._build_multimodal_content(message, media)

        # æ·»åŠ åˆ°æ¶ˆæ¯å†å²
        self.messages.append(user_message)

        # æ£€æŸ¥å¹¶å‹ç¼©ä¸Šä¸‹æ–‡
        if self.context_monitor:
            self.messages = self.context_monitor.check_and_compress(self.messages)

        # è°ƒç”¨ LLM
        response = await self.agent.generate_response(self.messages)

        # æ·»åŠ åŠ©æ‰‹å›å¤
        self.messages.append({"role": "assistant", "content": response})

        return response

    def _build_multimodal_content(self, text: str, media: List[str]) -> List[Dict]:
        """
        æ„å»ºå¤šæ¨¡æ€å†…å®¹

        Args:
            text: æ–‡æœ¬å†…å®¹
            media: åª’ä½“æ–‡ä»¶è·¯å¾„

        Returns:
            å¤šæ¨¡æ€å†…å®¹åˆ—è¡¨
        """
        import base64
        import mimetypes
        from pathlib import Path

        content = []

        # æ·»åŠ å›¾ç‰‡
        for path in media:
            p = Path(path)
            if not p.exists():
                continue

            mime, _ = mimetypes.guess_type(path)
            if not mime or not mime.startswith("image/"):
                continue

            # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
            b64 = base64.b64encode(p.read_bytes()).decode()
            content.append({
                "type": "image_url",
                "image_url": {"url": f"data:{mime};base64,{b64}"}
            })

        #æœ€åæ·»åŠ æ–‡æœ¬
        content.append({"type": "text", "text": text})

        return content
```

---

## ğŸ“Š é…ç½®é€‰é¡¹

### åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ ä¸Šä¸‹æ–‡ç›‘æ§é…ç½®

```yaml
# nanobot_config.yaml
agents:
  defaults:
    workspace: "~/.nanobot/workspace"
    model: "glm4.7"
    max_tokens: 8192
    temperature: 0.7
  main_agent:
    name: "Main Agent"
    description: "Main orchestration agent"

# ä¸Šä¸‹æ–‡ç®¡ç†é…ç½®
context_management:
  enabled: true  # æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡ç®¡ç†

  # çª—å£é…ç½®
  window:
    max_tokens: 128000  # æœ€å¤§ token æ•°ï¼ˆClaude 3.5 Sonnetï¼‰
    threshold_percent: 0.6  # è§¦å‘å‹ç¼©çš„é˜ˆå€¼ç™¾åˆ†æ¯”

  # å‹ç¼©é…ç½®
  compression:
    enabled: true
    algorithm: "intelligent"  # ç®—æ³•ï¼šintelligent, simple, aggressive
    preserve_system: true  # æ˜¯å¦ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
    preserve_last_n: 3  # ä¿ç•™æœ€å N æ¡ç”¨æˆ·æ¶ˆæ¯

  # ç›‘æ§é…ç½®
  monitoring:
    enabled: true
    log_compressions: true  # è®°å½•å‹ç¼©äº‹ä»¶
    save_compression_stats: true  # ä¿å­˜å‹ç¼©ç»Ÿè®¡
    stats_file: "~/.nanobot/workspace/debug/compression_stats.json"

  # ç¼“å­˜é…ç½®
  cache:
    enabled: true
    ttl: 300  # ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰
```

---

## ğŸ¨ é’©å­ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šè®°å½•å‹ç¼©äº‹ä»¶åˆ°æ–‡ä»¶

```python
def log_compression_event(**kwargs):
    """è®°å½•å‹ç¼©äº‹ä»¶åˆ°æ–‡ä»¶"""
    from datetime import datetime
    import json

    event = {
        "timestamp": datetime.now().isoformat(),
        "event": "context_compression",
        "details": kwargs
    }

    # å†™å…¥æ—¥å¿—æ–‡ä»¶
    log_file = Path.home() / ".nanobot" / "workspace" / "debug" / "compression_log.jsonl"
    log_file.parent.mkdir(parents=True, exist_ok=True)

    with open(log_file, "a", encoding="utf-8") as f:
        f.write(json.dumps(event, ensure_ascii=False) + "\n")

# æ³¨å†Œé’©å­
context_monitor.hooks.register("after_context_compression", log_compression_event)
```

### ç¤ºä¾‹ 2ï¼šå‘é€å‹ç¼©é€šçŸ¥

```python
async def notify_compression(**kwargs):
    """å‘é€å‹ç¼©é€šçŸ¥"""
    compression_ratio = kwargs.get("compression_ratio", 0)
    original_tokens = kwargs.get("original_tokens", 0)
    compressed_tokens = kwargs.get("compressed_tokens", 0)

    message = (
        f"âš ï¸ Context auto-compressed\n"
        f"Original: {original_tokens:,} tokens\n"
        f"Compressed: {compressed_tokens:,} tokens\n"
        f"Ratio: {compression_ratio:.1%}"
    )

    # é€šè¿‡é£ä¹¦å‘é€é€šçŸ¥
    await send_feishu_message(message)

# æ³¨å†Œé’©å­
context_monitor.hooks.register("after_context_compression", notify_compression)
```

### ç¤ºä¾‹ 3ï¼šåŠ¨æ€è°ƒæ•´é˜ˆå€¼

```python
def adjust_threshold(**kwargs):
    """æ ¹æ®ä½¿ç”¨æƒ…å†µåŠ¨æ€è°ƒæ•´é˜ˆå€¼"""
    original_tokens = kwargs.get("original_tokens", 0)
    max_tokens = kwargs.get("max_tokens", 128000)

    # å¦‚æœç»å¸¸æ¥è¿‘çª—å£ä¸Šé™ï¼Œæé«˜é˜ˆå€¼
    if original_tokens / max_tokens > 0.8:
        new_threshold = 0.5  # é™ä½åˆ° 50%ï¼Œæ›´æ—©è§¦å‘å‹ç¼©
        context_monitor.threshold = max_tokens * new_threshold
        logging.info(f"Adjusted compression threshold to {new_threshold:.0%}")

# æ³¨å†Œé’©å­
context_monitor.hooks.register("after_context_compression", adjust_threshold)
```

### ç¤ºä¾‹ï¼šåœ¨å‹ç¼©æ—¶åˆ†ææ¨¡å¼

```python
async def analyze_compression_patterns(**kwargs):
    """åˆ†æå‹ç¼©æ¨¡å¼"""
    original_count = kwargs.get("original_count", 0)
    compressed_count = kwargs.get("compressed_count", 0)

    # è®¡ç®—è¢«å‹ç¼©çš„æ¶ˆæ¯æ¯”ä¾‹
    ratio = (original_count - compressed_count) / original_count if original_count > 0 else 0

    # å¦‚æœå‹ç¼©æ¯”ä¾‹è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨é•¿å¯¹è¯
    if ratio > 0.5:
        logging.warning(
            f"High compression ratio detected: {ratio:.1%}. "
            "Consider increasing max_tokens or changing conversation strategy."
        )

# æ³¨å†Œé’©å­
context_monitor.hooks.register("after_context_compression", analyze_compression_patterns)
```

---

## ğŸ“ˆ ç›‘æ§å’Œç»Ÿè®¡

### è·å–å‹ç¼©ç»Ÿè®¡ä¿¡æ¯

```python
# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = context_monitor.get_stats()
print(f"Total checks: {stats['total_checks']}")
print(f"Compressions triggered: {stats['compressions_triggered']}")
print(f"Messages compressed: {stats['messages_compressed']}")
print(f"Tokens saved: {stats['tokens_saved']}")
```

### è¾“å‡ºç¤ºä¾‹

```
Context Monitor Statistics
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total checks:               1,234
Compressions triggered:         89
Messages compressed:          456
Tokens saved:           1,234,567

Compression rate:             7.2% (89/1234)
Average messages/compression:  5.1
Average tokens saved:     13,871
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ¯ é’©å­åˆ—è¡¨

| é’©å­åç§° | è§¦å‘æ—¶æœº | å‚æ•° | ç”¨é€” |
|---------|---------|------|------|
| before_context_compression | ä¸Šä¸‹æ–‡å‹ç¼©å‰ | current_tokens, max_tokens, threshold, messages_count | è®°å½•æ—¥å¿—ã€åˆ†ææ¨¡å¼ |
| after_context_compression | ä¸Šä¸‹æ–‡å‹ç¼©å | original_count, compressed_count, original_tokens, compressed_tokens, compression_ratio | è®°å½•ç»Ÿè®¡ã€å‘é€é€šçŸ¥ã€åŠ¨æ€è°ƒæ•´ |

---

## âœ… å®æ–½æ£€æŸ¥æ¸…å•

### æ ¸å¿ƒåŠŸèƒ½
- [ ] å®ç° ContextMonitor ç±»
- [ ] å®ç° token è®¡æ•°æ–¹æ³•
- [ ] å®ç°æ¶ˆæ¯å‹ç¼©æ–¹æ³•
- [ ] å®ç°é˜ˆå€¼æ£€æŸ¥
- [ ] é›†æˆ ContextCompressorV2

### é›†æˆåˆ° Agent
- [ ] ä¿®æ”¹ AgentLoop é›†æˆç›‘æ§
- [ ] åœ¨ process_message ä¸­è°ƒç”¨æ£€æŸ¥
- [ ] æ”¯æŒå¤šæ¨¡æ€å†…å®¹

### é…ç½®æ”¯æŒ
- [ ] æ·»åŠ é…ç½®é€‰é¡¹
- [ ] æ”¯æŒå¯ç”¨/ç¦ç”¨
- [ ] æ”¯æŒè‡ªå®šä¹‰é˜ˆå€¼
- [ ] æ”¯æŒé€‰æ‹©å‹ç¼©ç­–ç•¥

### é’©å­ç³»ç»Ÿ
- [ ] å®ç° before_context_compression é’©å­
- [ ] å®ç° after_context_compression é’©å­
- [ ] æ³¨å†Œé»˜è®¤é’©å­
- [ ] æ”¯æŒè‡ªå®šä¹‰é’©å­

### æµ‹è¯•
- [ ] æµ‹è¯•é˜ˆå€¼è§¦å‘
- [ ] æµ‹è¯•å‹ç¼©æ•ˆæœ
- [ ] æµ‹è¯•å¤šæ¨¡æ€æ¶ˆæ¯
- [ ] æµ‹è¯•é’©å­æ‰§è¡Œ
- [ ] æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯

---

## ğŸ” ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šåŸºæœ¬ä½¿ç”¨

```python
from nanobot.agent.context_compressor_v2 import ContextCompressor
from nanobot.agent.context_monitor import ContextMonitor

# åˆ›å»ºå‹ç¼©å™¨
compressor = ContextCompressor()

# åˆ›å»ºç›‘æ§å™¨ï¼ˆ60% é˜ˆå€¼ï¼‰
monitor = ContextMonitor(
    context_compressor=compressor,
    max_tokens=128000,
    threshold_percent=0.6
)

# å¤„ç†æ¶ˆæ¯
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"},
    {"role": "assistant", "content": "Hi there!"},
    # ... æ›´å¤šæ¶ˆæ¯
]

# æ£€æŸ¥å¹¶å‹ç¼©
compressed_messages = monitor.check_and_compress(messages)

# è·å–ç»Ÿè®¡
stats = monitor.get_stats()
print(f"Compressions triggered: {stats['compressions_triggered']}")
```

### ç¤ºä¾‹ 2ï¼šä¸ Agent Loop é›†æˆ

```python
from nanobot.agent.loop import AgentLoop
from nanobot.agent.context_monitor import ContextMonitor

# åˆ›å»ºä¸Šä¸‹æ–‡ç›‘æ§å™¨
context_monitor = ContextMonitor(
        context_compressor=compressor,
        max_tokens=128000,
        threshold_percent=0.6
)

# åˆ›å»º Agent Loopï¼ˆä¼ å…¥ç›‘æ§å™¨ï¼‰
loop = AgentLoop(
    agent=main_agent,
    context_monitor=context_monitor
)

# å¤„ç†æ¶ˆæ¯ï¼ˆè‡ªåŠ¨ç›‘æ§å’Œå‹ç¼©ï¼‰
response = await loop.process_message("What is the weather today?")
```

### ç¤ºä¾‹ 3ï¼šè‡ªå®šä¹‰é’©å­

```python
# æ³¨å†Œè‡ªå®šä¹‰é’©å­
def my_compression_hook(**kwargs):
    compression_ratio = kwargs.get("compression_ratio", 0)
    print(f"Compression ratio: {compression_ratio:.1%}")

context_monitor.hooks.register(
    "after_context_compression",
    my_compression_hook
)
```

---

## ğŸ“ æ€»ç»“

ä¸Šä¸‹æ–‡ç›‘æ§é’©å­ç³»ç»Ÿæä¾›äº†è‡ªåŠ¨åŒ–çš„ä¸Šä¸‹æ–‡ç®¡ç†ï¼š

âœ… **å®æ—¶ç›‘æ§** - åœ¨æ¯æ¬¡æ·»åŠ æ¶ˆæ¯åæ£€æŸ¥é•¿åº¦
âœ… **é˜ˆå€¼è§¦å‘** - è¾¾åˆ° 60% æ—¶è‡ªåŠ¨å‹ç¼©
âœ… **æ™ºèƒ½å‹ç¼©** - ä½¿ç”¨ ContextCompressorV2 è¿›è¡Œå‹ç¼©
âœ… **å¯é…ç½®** - æ”¯æŒè‡ªå®šä¹‰é˜ˆå€¼å’Œç­–ç•¥
âœ… **é’©å­æ‰©å±•** - æ”¯æŒå‹ç¼©å‰åé’©å­
âœ… **ç»Ÿè®¡ç›‘æ§** - æä¾›è¯¦ç»†çš„å‹ç¼©ç»Ÿè®¡
